{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Managing and evaluating generative AI systems\n",
    "\n",
    "Date: 25 Sept 2025\n",
    "\n",
    "## GenAIOps vs MLOps\n",
    "\n",
    "### Traditional MLOps Learning Lifecycle\n",
    "\n",
    "1. Business problem\n",
    "2. Goal definition: goal to solve the problem but also goal in terms of latency, etc. So you can monitor if it's not detrimental for the UX for example. You define the baseline of the model: the model will be good at these numbers.\n",
    "3. Data collection and prep: takes 80% of the work! very important to test the data and understand how many data points you need to build a good model (you need many data, otherwise GIGO!) You need to have a proper data lake with data monitoring in place before building the model, because if you have bad data, you won't have a good model. Also beware of GDPR when choosing the data, no sensitive data into the model!\n",
    "4. Feature engineering\n",
    "5. Model training\n",
    "6. Model evaluation: if the expected range is not met (i.e. the model is overfitting or underfitting), we go back to step (3) and loop until we pass evaluation\n",
    "7. Model registration: where you document the model, so that it is reproducible!\n",
    "8. Model deployment and serving\n",
    "9. Model monitoring: monitor that there is no data drift, that the model is still working at the right range that we set in our goal definition (baseline). Very crucial to ensure that the new trends are capture and see if new data make the model drift or continue to product the expected results within our acceptable margin (based on our goals).\n",
    "10. Model improvement --> back to step (3) and loop: this means that a model needs to be scalable because a model needs to be retrained continuously, so you need to feed in new data continuously --> it has to be scalable!\n",
    "\n",
    "### LLMLOps Lifecycle\n",
    "\n",
    "1. Business problem\n",
    "2. Goal definition\n",
    "3. Data collection \n",
    "4. Feature engineering done by the big players (Mistral, OpenAI, Anthropic, etc.): We are not building models anymore, we use existing models\n",
    "5. Optional: Fine-tuning of existing models (open source only)\n",
    "5. Deployment of models (as is or fine-tuned)\n",
    "6. Use the model directly with prompt engineering, or use agents, or RAG\n",
    "7. Evaluation: very important because we need to be sure that things happen how we defined them in our goals\n",
    "\n",
    "### Foundational models\n",
    "\n",
    "The future is larger models (more and more billions of parameters; e.g. from GPT-2 to GPT-3 we went from 1B of parameters to 100B of parameters) but also smaller models that are more specialized for specific industries and produce better results because their data for training is more focused. They will use smaller models from big players and fine tune them; not build new foundational models from scratch because too costly (GPUs, etc.; cost of training GPT-3.5: 20M USD), very heavy work and you don't even know if it's going to work at the end.\n",
    "\n",
    "So alternatives are:\n",
    "- Fine-Tuning\n",
    "- Prompt Engineering\n",
    "- RAG\n",
    "\n",
    "## Fine-Tuning\n",
    "\n",
    "2 ways to do it:\n",
    "1. Parameter-Efficient Fine-Tuning (PEFT): Freeze the pretrained transformer (with specific weight, etc.) and add new layers on top (easiest); update only parts of the model\n",
    "2. Full Fine-Tuning: Retrain the pretrained transformer by adding new layers and revisit then all parameters\n",
    "\n",
    "Fine-tuning continues the training of the model on a smaller, narrower dataset. \n",
    "\n",
    "**Fine-tuning vs. RAG:**\n",
    "With fine-tuning the context is built into the model vs. RAG: add context on top of the model.\n",
    "With fine-tuning once the data is in there, you can't change it vs. RAG: you can change data anytime because you can always choose which context you pass.\n",
    "\n",
    "To really fine-tune a big model we would need GPU, etc. We can do fine-tuning on our own computer but only with small models. E.g.:\n",
    "- Fine-tuning LLaMA 7B parameters with 1GPU and 25M total tokens (size of dataset x nbr of times we run it (epochs)): it will take over 5h to fine-tune and cost 15USD\n",
    "- Fine-tuning GPT3 175B parameters with 32GPU (to be faster) and 500M tokens: it will take 2600h to fine-tune and cost 200k USD!\n",
    "\n",
    "Fine-tuning is good to use when the data we want to add are not going to evolve, e.g. legal data, medical, etc. \n",
    "\n",
    "Always start small and specific, then evaluate, then move up. Never start with a big model!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
