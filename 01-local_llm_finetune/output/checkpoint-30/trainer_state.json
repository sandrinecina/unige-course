{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 30,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 10.750892639160156,
      "learning_rate": 0.0004,
      "loss": 7.9829,
      "step": 1
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 18.82411003112793,
      "learning_rate": 0.00038666666666666667,
      "loss": 11.1675,
      "step": 2
    },
    {
      "epoch": 1.0,
      "grad_norm": 21.73029136657715,
      "learning_rate": 0.0003733333333333334,
      "loss": 5.1929,
      "step": 3
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 16.529298782348633,
      "learning_rate": 0.00036,
      "loss": 4.4098,
      "step": 4
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 25.69045066833496,
      "learning_rate": 0.00034666666666666667,
      "loss": 4.4021,
      "step": 5
    },
    {
      "epoch": 2.0,
      "grad_norm": 27.026687622070312,
      "learning_rate": 0.0003333333333333334,
      "loss": 5.0929,
      "step": 6
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 7.484911918640137,
      "learning_rate": 0.00032,
      "loss": 3.6305,
      "step": 7
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 18.759178161621094,
      "learning_rate": 0.0003066666666666667,
      "loss": 3.7643,
      "step": 8
    },
    {
      "epoch": 3.0,
      "grad_norm": 9.314629554748535,
      "learning_rate": 0.0002933333333333333,
      "loss": 2.424,
      "step": 9
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 15.159733772277832,
      "learning_rate": 0.00028,
      "loss": 2.3873,
      "step": 10
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 4.236377716064453,
      "learning_rate": 0.0002666666666666667,
      "loss": 3.0311,
      "step": 11
    },
    {
      "epoch": 4.0,
      "grad_norm": 3.1518068313598633,
      "learning_rate": 0.00025333333333333333,
      "loss": 1.9776,
      "step": 12
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 2.8993358612060547,
      "learning_rate": 0.00024,
      "loss": 1.9042,
      "step": 13
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 5.032249927520752,
      "learning_rate": 0.00022666666666666668,
      "loss": 1.7921,
      "step": 14
    },
    {
      "epoch": 5.0,
      "grad_norm": 3.6213128566741943,
      "learning_rate": 0.00021333333333333333,
      "loss": 2.7958,
      "step": 15
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 3.5866518020629883,
      "learning_rate": 0.0002,
      "loss": 2.7343,
      "step": 16
    },
    {
      "epoch": 5.666666666666667,
      "grad_norm": 2.6216061115264893,
      "learning_rate": 0.0001866666666666667,
      "loss": 1.6571,
      "step": 17
    },
    {
      "epoch": 6.0,
      "grad_norm": 2.291719913482666,
      "learning_rate": 0.00017333333333333334,
      "loss": 1.5904,
      "step": 18
    },
    {
      "epoch": 6.333333333333333,
      "grad_norm": 2.220017194747925,
      "learning_rate": 0.00016,
      "loss": 1.558,
      "step": 19
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 2.6249539852142334,
      "learning_rate": 0.00014666666666666666,
      "loss": 1.5142,
      "step": 20
    },
    {
      "epoch": 7.0,
      "grad_norm": 3.4323928356170654,
      "learning_rate": 0.00013333333333333334,
      "loss": 2.4983,
      "step": 21
    },
    {
      "epoch": 7.333333333333333,
      "grad_norm": 2.2364983558654785,
      "learning_rate": 0.00012,
      "loss": 1.4506,
      "step": 22
    },
    {
      "epoch": 7.666666666666667,
      "grad_norm": 2.592963933944702,
      "learning_rate": 0.00010666666666666667,
      "loss": 1.3914,
      "step": 23
    },
    {
      "epoch": 8.0,
      "grad_norm": 3.2029683589935303,
      "learning_rate": 9.333333333333334e-05,
      "loss": 2.3936,
      "step": 24
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 3.1254286766052246,
      "learning_rate": 8e-05,
      "loss": 2.3633,
      "step": 25
    },
    {
      "epoch": 8.666666666666666,
      "grad_norm": 2.562934637069702,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.3037,
      "step": 26
    },
    {
      "epoch": 9.0,
      "grad_norm": 2.3138248920440674,
      "learning_rate": 5.333333333333333e-05,
      "loss": 1.3362,
      "step": 27
    },
    {
      "epoch": 9.333333333333334,
      "grad_norm": 3.0752928256988525,
      "learning_rate": 4e-05,
      "loss": 2.2919,
      "step": 28
    },
    {
      "epoch": 9.666666666666666,
      "grad_norm": 2.324700117111206,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.3133,
      "step": 29
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.54506254196167,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.2513,
      "step": 30
    }
  ],
  "logging_steps": 1,
  "max_steps": 30,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 11930558791680.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
